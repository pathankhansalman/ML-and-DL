{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1084f7c6-0063-4329-8653-1bd5ccd71996",
   "metadata": {},
   "source": [
    "## Deep ensembles based training implementation\n",
    "\n",
    "Implementing the methodology outlined in https://arxiv.org/pdf/1612.01474, except for the adversarial training. To modify to adversarial training, add gaussian noise to the training samples. Credit to the work goes completely to the authors and other parties mentioned in the paper, as per the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b83bc-2a3d-4b97-bf4e-3f176b4d1e8e",
   "metadata": {},
   "source": [
    "### Defining model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a634228e-cd14-430f-8b33-edee2c8849a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def _deep_ens_loss_(x, y):\n",
    "    return torch.mean(torch.log(x[:, 1]**2)/2 + (y - x[:, 0])**2/(2*x[:, 1]**2))\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Define layers\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply ReLU activation to hidden layer\n",
    "        x = torch.relu(self.hidden(x))\n",
    "        # Apply output layer (no activation here, often softmax is applied externally if needed)\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c41a8b-6939-4fd1-a59d-d1cf42ca9be4",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "10d626c9-b91f-4cdd-a4fb-0dcdba076395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 14850.8616\n",
      "Epoch [2/20], Loss: 14832.2363\n",
      "Epoch [3/20], Loss: 14832.9243\n",
      "Epoch [4/20], Loss: 14832.1628\n",
      "Epoch [5/20], Loss: 14835.2836\n",
      "Epoch [6/20], Loss: 14834.4737\n",
      "Epoch [7/20], Loss: 14834.2676\n",
      "Epoch [8/20], Loss: 14837.1324\n",
      "Epoch [9/20], Loss: 14887.1743\n",
      "Epoch [10/20], Loss: 14833.3569\n",
      "Epoch [11/20], Loss: 14832.8624\n",
      "Epoch [12/20], Loss: 14833.0183\n",
      "Epoch [13/20], Loss: 14833.2853\n",
      "Epoch [14/20], Loss: 14899.0095\n",
      "Epoch [15/20], Loss: 16218.0776\n",
      "Epoch [16/20], Loss: 14835.7335\n",
      "Epoch [17/20], Loss: 14833.5402\n",
      "Epoch [18/20], Loss: 15104.6339\n",
      "Epoch [19/20], Loss: 14833.6117\n",
      "Epoch [20/20], Loss: 14833.3544\n",
      "Epoch [1/20], Loss: 8492463.3216\n",
      "Epoch [2/20], Loss: 8492108.1181\n",
      "Epoch [3/20], Loss: 8492105.9874\n",
      "Epoch [4/20], Loss: 8492051.4348\n",
      "Epoch [5/20], Loss: 8492058.3910\n",
      "Epoch [6/20], Loss: 8492074.2371\n",
      "Epoch [7/20], Loss: 8492068.8603\n",
      "Epoch [8/20], Loss: 8492051.3046\n",
      "Epoch [9/20], Loss: 8494833.5934\n",
      "Epoch [10/20], Loss: 8492055.7010\n",
      "Epoch [11/20], Loss: 8492065.3097\n",
      "Epoch [12/20], Loss: 8492051.7324\n",
      "Epoch [13/20], Loss: 8492057.5615\n",
      "Epoch [14/20], Loss: 8492051.4511\n",
      "Epoch [15/20], Loss: 8492053.4749\n",
      "Epoch [16/20], Loss: 8492057.5071\n",
      "Epoch [17/20], Loss: 8494763.7268\n",
      "Epoch [18/20], Loss: 8492123.4568\n",
      "Epoch [19/20], Loss: 8651907.4708\n",
      "Epoch [20/20], Loss: 8492594.0088\n",
      "Epoch [1/20], Loss: 30045.1908\n",
      "Epoch [2/20], Loss: 30045.8852\n",
      "Epoch [3/20], Loss: 30045.3754\n",
      "Epoch [4/20], Loss: 30045.2204\n",
      "Epoch [5/20], Loss: 30045.2895\n",
      "Epoch [6/20], Loss: 30045.2026\n",
      "Epoch [7/20], Loss: 30045.1975\n",
      "Epoch [8/20], Loss: 30045.2505\n",
      "Epoch [9/20], Loss: 30045.3443\n",
      "Epoch [10/20], Loss: 30045.2625\n",
      "Epoch [11/20], Loss: 30045.2762\n",
      "Epoch [12/20], Loss: 30045.2361\n",
      "Epoch [13/20], Loss: 30045.2870\n",
      "Epoch [14/20], Loss: 30045.2385\n",
      "Epoch [15/20], Loss: 30045.5733\n",
      "Epoch [16/20], Loss: 30045.2785\n",
      "Epoch [17/20], Loss: 30045.2882\n",
      "Epoch [18/20], Loss: 30045.4815\n",
      "Epoch [19/20], Loss: 30045.2404\n",
      "Epoch [20/20], Loss: 30045.3280\n",
      "Epoch [1/20], Loss: 48002.5052\n",
      "Epoch [2/20], Loss: 48001.7685\n",
      "Epoch [3/20], Loss: 48001.7443\n",
      "Epoch [4/20], Loss: 48001.7441\n",
      "Epoch [5/20], Loss: 48002.4501\n",
      "Epoch [6/20], Loss: 48001.7619\n",
      "Epoch [7/20], Loss: 382644.0332\n",
      "Epoch [8/20], Loss: 48001.7631\n",
      "Epoch [9/20], Loss: 48001.7595\n",
      "Epoch [10/20], Loss: 48001.7868\n",
      "Epoch [11/20], Loss: 48001.7749\n",
      "Epoch [12/20], Loss: 48001.9472\n",
      "Epoch [13/20], Loss: 48001.7771\n",
      "Epoch [14/20], Loss: 48001.7564\n",
      "Epoch [15/20], Loss: 48001.9448\n",
      "Epoch [16/20], Loss: 48003.2545\n",
      "Epoch [17/20], Loss: 48001.7531\n",
      "Epoch [18/20], Loss: 48001.8129\n",
      "Epoch [19/20], Loss: 48001.7923\n",
      "Epoch [20/20], Loss: 48001.7540\n",
      "Epoch [1/20], Loss: 37277.2128\n",
      "Epoch [2/20], Loss: 37289.0241\n",
      "Epoch [3/20], Loss: 37276.4766\n",
      "Epoch [4/20], Loss: 37288.5894\n",
      "Epoch [5/20], Loss: 37276.5336\n",
      "Epoch [6/20], Loss: 37276.4112\n",
      "Epoch [7/20], Loss: 37276.4376\n",
      "Epoch [8/20], Loss: 37277.2212\n",
      "Epoch [9/20], Loss: 37276.3454\n",
      "Epoch [10/20], Loss: 37278.2068\n",
      "Epoch [11/20], Loss: 38774.2281\n",
      "Epoch [12/20], Loss: 37276.4930\n",
      "Epoch [13/20], Loss: 37285.5006\n",
      "Epoch [14/20], Loss: 37357.6968\n",
      "Epoch [15/20], Loss: 37452.3152\n",
      "Epoch [16/20], Loss: 37301.6354\n",
      "Epoch [17/20], Loss: 37276.3363\n",
      "Epoch [18/20], Loss: 37277.3397\n",
      "Epoch [19/20], Loss: 37276.7962\n",
      "Epoch [20/20], Loss: 37277.0113\n",
      "Epoch [1/20], Loss: 32116.8009\n",
      "Epoch [2/20], Loss: 32120.5405\n",
      "Epoch [3/20], Loss: 32113.9088\n",
      "Epoch [4/20], Loss: 32113.5842\n",
      "Epoch [5/20], Loss: 32114.0304\n",
      "Epoch [6/20], Loss: 32113.7338\n",
      "Epoch [7/20], Loss: 32113.6820\n",
      "Epoch [8/20], Loss: 32113.6379\n",
      "Epoch [9/20], Loss: 32115.0260\n",
      "Epoch [10/20], Loss: 32113.5925\n",
      "Epoch [11/20], Loss: 32113.7924\n",
      "Epoch [12/20], Loss: 32113.6428\n",
      "Epoch [13/20], Loss: 32113.6299\n",
      "Epoch [14/20], Loss: 32212.5207\n",
      "Epoch [15/20], Loss: 32114.2768\n",
      "Epoch [16/20], Loss: 32113.5890\n",
      "Epoch [17/20], Loss: 32116.1085\n",
      "Epoch [18/20], Loss: 32116.3377\n",
      "Epoch [19/20], Loss: 32113.9510\n",
      "Epoch [20/20], Loss: 32113.8026\n",
      "Epoch [1/20], Loss: 45135.0053\n",
      "Epoch [2/20], Loss: 45292.2900\n",
      "Epoch [3/20], Loss: 45135.2223\n",
      "Epoch [4/20], Loss: 45173.0208\n",
      "Epoch [5/20], Loss: 45257.6678\n",
      "Epoch [6/20], Loss: 45135.6476\n",
      "Epoch [7/20], Loss: 45415.1582\n",
      "Epoch [8/20], Loss: 45137.3666\n",
      "Epoch [9/20], Loss: 45136.6257\n",
      "Epoch [10/20], Loss: 45135.3915\n",
      "Epoch [11/20], Loss: 45138.4202\n",
      "Epoch [12/20], Loss: 45135.2597\n",
      "Epoch [13/20], Loss: 45626.7279\n",
      "Epoch [14/20], Loss: 45641.0403\n",
      "Epoch [15/20], Loss: 45439.4506\n",
      "Epoch [16/20], Loss: 45136.1689\n",
      "Epoch [17/20], Loss: 45136.4819\n",
      "Epoch [18/20], Loss: 45139.7793\n",
      "Epoch [19/20], Loss: 45140.0414\n",
      "Epoch [20/20], Loss: 45138.8034\n",
      "Epoch [1/20], Loss: 431963.0019\n",
      "Epoch [2/20], Loss: 431962.6982\n",
      "Epoch [3/20], Loss: 431962.6239\n",
      "Epoch [4/20], Loss: 431969.9201\n",
      "Epoch [5/20], Loss: 431975.7239\n",
      "Epoch [6/20], Loss: 431960.8909\n",
      "Epoch [7/20], Loss: 431965.9311\n",
      "Epoch [8/20], Loss: 432708.8118\n",
      "Epoch [9/20], Loss: 431961.4937\n",
      "Epoch [10/20], Loss: 431976.4710\n",
      "Epoch [11/20], Loss: 431962.4281\n",
      "Epoch [12/20], Loss: 431985.5741\n",
      "Epoch [13/20], Loss: 431961.9058\n",
      "Epoch [14/20], Loss: 431963.3834\n",
      "Epoch [15/20], Loss: 431962.7219\n",
      "Epoch [16/20], Loss: 431989.2974\n",
      "Epoch [17/20], Loss: 431964.6432\n",
      "Epoch [18/20], Loss: 431963.7972\n",
      "Epoch [19/20], Loss: 431967.1935\n",
      "Epoch [20/20], Loss: 432214.1036\n",
      "Epoch [1/20], Loss: 56547.7648\n",
      "Epoch [2/20], Loss: 56533.0412\n",
      "Epoch [3/20], Loss: 56612.3729\n",
      "Epoch [4/20], Loss: 56533.0685\n",
      "Epoch [5/20], Loss: 56534.1020\n",
      "Epoch [6/20], Loss: 56532.7476\n",
      "Epoch [7/20], Loss: 56539.9398\n",
      "Epoch [8/20], Loss: 56585.4737\n",
      "Epoch [9/20], Loss: 56643.4977\n",
      "Epoch [10/20], Loss: 56534.2488\n",
      "Epoch [11/20], Loss: 56533.6655\n",
      "Epoch [12/20], Loss: 56543.1611\n",
      "Epoch [13/20], Loss: 56533.9991\n",
      "Epoch [14/20], Loss: 56550.2847\n",
      "Epoch [15/20], Loss: 56532.9062\n",
      "Epoch [16/20], Loss: 56533.2223\n",
      "Epoch [17/20], Loss: 56534.2813\n",
      "Epoch [18/20], Loss: 56534.4303\n",
      "Epoch [19/20], Loss: 56533.3941\n",
      "Epoch [20/20], Loss: 56533.1322\n",
      "Epoch [1/20], Loss: 3064700.5556\n",
      "Epoch [2/20], Loss: 3064750.2939\n",
      "Epoch [3/20], Loss: 3064700.7893\n",
      "Epoch [4/20], Loss: 3064700.6253\n",
      "Epoch [5/20], Loss: 3064700.6941\n",
      "Epoch [6/20], Loss: 3064700.5688\n",
      "Epoch [7/20], Loss: 3064795.8605\n",
      "Epoch [8/20], Loss: 3064700.4346\n",
      "Epoch [9/20], Loss: 3064703.4786\n",
      "Epoch [10/20], Loss: 3064703.9203\n",
      "Epoch [11/20], Loss: 3064700.9401\n",
      "Epoch [12/20], Loss: 3064700.4123\n",
      "Epoch [13/20], Loss: 3064700.8621\n",
      "Epoch [14/20], Loss: 3064700.7434\n",
      "Epoch [15/20], Loss: 3064700.4982\n",
      "Epoch [16/20], Loss: 3064748.6546\n",
      "Epoch [17/20], Loss: 3064700.3694\n",
      "Epoch [18/20], Loss: 3064700.7492\n",
      "Epoch [19/20], Loss: 3064700.8253\n",
      "Epoch [20/20], Loss: 3064700.6384\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 10     # Number of input features\n",
    "hidden_size = 5     # Number of neurons in the hidden layer\n",
    "output_size = 2     # Number of output neurons (for a binary classification task)\n",
    "num_epochs = 20     # Number of training epochs\n",
    "batch_size = 128     # Batch size for training\n",
    "learning_rate = 0.0001  # Learning rate for the optimizer\n",
    "num_ens = 10  # Number of ensembles\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = _deep_ens_loss_\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Use SGD optimizer\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "num_samples = 10000\n",
    "X = torch.randn(num_samples, input_size)  # Randomly generated input features\n",
    "y = torch.randn(num_samples,)  # Randomly generated binary labels (0 or 1)\n",
    "dataset = TensorDataset(X, y)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "models = []\n",
    "for i in range(num_ens):\n",
    "    # Instantiate the model\n",
    "    model = SimpleNN(input_size, hidden_size, output_size)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in data_loader:\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(data_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf07b8-c5da-4db5-8ad3-800c8b43d4b6",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9045c714-cef1-4087-b377-1d8987121fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset and DataLoader\n",
    "test_num_samples = 3000\n",
    "X_test = torch.randn(test_num_samples, input_size)  # Randomly generated input features\n",
    "y_test = torch.randn(test_num_samples,)   # Randomly generated binary labels (0 or 1)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "for test_inputs, _ in test_data_loader:\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        test_outputs = [model(test_inputs) for model in models]\n",
    "test_means = reduce(lambda x, y: torch.add(x, y), [output[:, 0] for output in test_outputs])/num_ens\n",
    "test_var = reduce(lambda x, y: torch.add(x, y),\n",
    "                  [torch.add(torch.pow(output[:, 0], 2), torch.pow(output[:, 1], 2))\n",
    "                   for output in test_outputs])/num_ens - torch.pow(test_means, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725039d0-28c3-45c5-b8cc-7b6bcb66630d",
   "metadata": {},
   "source": [
    "test_means has the mean and test_var has the variance for gaussian distribution of prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a8895-8664-454a-acc5-262ace8bc0df",
   "metadata": {},
   "source": [
    "This plot below shows the distribution of the number of standard deviations each value in our test set is away from the mean (mean and standard deviations as calculated above). We expect the bulk to be in -2 to 2 (95% CI), and as expected, close to 2000 out of 3000 test samples are within 95% CI. A higher number of ensembles will improve this even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "761c06bd-8725-48d7-8bc1-512539fb9683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   3.,   6.,   0.,   6.,   7.,  10.,   7.,  13.,  10.,\n",
       "         23.,  17.,  33.,  37.,  52.,  45.,  61.,  92., 104., 121., 130.,\n",
       "        132., 133., 139., 159., 174., 165., 157., 167., 139., 143., 117.,\n",
       "         88., 103.,  81.,  68.,  61.,  42.,  34.,  30.,  22.,  15.,  17.,\n",
       "         15.,   7.,   5.,   3.,   3.,   3.]),\n",
       " array([-7.80539036, -7.50426912, -7.20314837, -6.90202713, -6.60090637,\n",
       "        -6.29978514, -5.99866438, -5.69754314, -5.39642239, -5.09530115,\n",
       "        -4.79418039, -4.49305916, -4.1919384 , -3.89081717, -3.58969617,\n",
       "        -3.28857517, -2.98745418, -2.68633318, -2.38521218, -2.08409095,\n",
       "        -1.78297007, -1.48184907, -1.18072796, -0.87960702, -0.57848597,\n",
       "        -0.27736497,  0.02375605,  0.32487705,  0.62599808,  0.92711908,\n",
       "         1.22824013,  1.52936113,  1.83048213,  2.13160324,  2.43272424,\n",
       "         2.73384523,  3.03496623,  3.33608723,  3.63720822,  3.93832922,\n",
       "         4.23945045,  4.54057121,  4.84169245,  5.14281321,  5.44393444,\n",
       "         5.7450552 ,  6.04617643,  6.34729719,  6.64841843,  6.94953918,\n",
       "         7.25066042]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(torch.div(torch.sub(y_test, test_means), torch.sqrt(test_var)), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "60630c5d-fce5-499c-9e31-ff7119743acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1905\n",
       "True     1095\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(torch.abs(torch.div(torch.sub(y_test, test_means), torch.sqrt(test_var))) > 2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdce83-5d0d-4a95-bef7-a36f02dacc45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
